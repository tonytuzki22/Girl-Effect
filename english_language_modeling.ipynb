{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RAO7Js0X_u7X"
   },
   "source": [
    "# English Message Modeling \n",
    "\n",
    "This notebook explores how we can analyze messages and their associated category, and how we can use spellcheck. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gUcqXXxqM1Uj"
   },
   "outputs": [],
   "source": [
    "# import statements\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import string\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import LSTM, Dense, BatchNormalization, Dropout, Bidirectional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 30598,
     "status": "ok",
     "timestamp": 1606988884226,
     "user": {
      "displayName": "Neha Hudait",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiIKoKLUeQlnxxPDix_z2dV5i0n4W4cDcYvJWmzDw=s64",
      "userId": "04178890623871470592"
     },
     "user_tz": 300
    },
    "id": "FVkzduNHNb2w",
    "outputId": "df80764c-1c27-43a9-cb52-c84bd9ac1f91"
   },
   "outputs": [],
   "source": [
    "# setting up colab\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive',force_remount=True)\n",
    "MY_DRIVE = \"drive/My Drive/\"\n",
    "root_folder = os.path.join(MY_DRIVE, \"girl_effect\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g3S9JchqO2sZ"
   },
   "outputs": [],
   "source": [
    "# cleaning data \n",
    "df = pd.read_csv(os.path.join(root_folder,\"chatbots_data_new1.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "executionInfo": {
     "elapsed": 250,
     "status": "ok",
     "timestamp": 1606988887369,
     "user": {
      "displayName": "Neha Hudait",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiIKoKLUeQlnxxPDix_z2dV5i0n4W4cDcYvJWmzDw=s64",
      "userId": "04178890623871470592"
     },
     "user_tz": 300
    },
    "id": "nMYujQl-TTp9",
    "outputId": "edee94b7-da29-42d7-a95d-cb7519271f46"
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QQWF3gyr0iO0"
   },
   "source": [
    "# Getting English DataFrame\n",
    "For this part, I just wanted to test out the LSTM Model creation, so I picked all the entries which would correspond to the message being in English and specifically within the Big Sis chatbot. I opted to approach the Chhaa Jaa dataset in a separate notebook.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f_XZJ32hWDZF"
   },
   "outputs": [],
   "source": [
    "english = df[df[\"Org Name\"] == \"Big Sis V3\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "executionInfo": {
     "elapsed": 443,
     "status": "ok",
     "timestamp": 1606988930706,
     "user": {
      "displayName": "Neha Hudait",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiIKoKLUeQlnxxPDix_z2dV5i0n4W4cDcYvJWmzDw=s64",
      "userId": "04178890623871470592"
     },
     "user_tz": 300
    },
    "id": "m0g9Q50DWRwZ",
    "outputId": "f34791e7-0472-4a5c-f4cc-eda236018222"
   },
   "outputs": [],
   "source": [
    "english"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zKr-IW9D0ztE"
   },
   "source": [
    "# Spell Check\n",
    "The first step that I wanted to do was explore spell check. I found a pretty good library called pyspellchecker which allows us to replace words with the most likely autocrrected word (no change if it's already a valid word). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3597,
     "status": "ok",
     "timestamp": 1606988944910,
     "user": {
      "displayName": "Neha Hudait",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiIKoKLUeQlnxxPDix_z2dV5i0n4W4cDcYvJWmzDw=s64",
      "userId": "04178890623871470592"
     },
     "user_tz": 300
    },
    "id": "sqN9sqL9WSg-",
    "outputId": "dfa996c8-056f-4e4f-87ae-a4023d0df77a"
   },
   "outputs": [],
   "source": [
    "# installing the spell checker \n",
    "!pip install pyspellchecker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rAvHVm76Y1cm"
   },
   "outputs": [],
   "source": [
    "from spellchecker import SpellChecker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X_1KyJE0bW2v"
   },
   "outputs": [],
   "source": [
    "spell = SpellChecker()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b5jmkwzr1LrN"
   },
   "source": [
    "# Applying Spell check to our data frame\n",
    "We lowercase and apply spell check tothe column message in our data frame. This process takes quite a bit of time (it individually checks each word)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O6Fwjv_HbznC"
   },
   "outputs": [],
   "source": [
    "# function to spell check the word \n",
    "def corrected_string(sentence):\n",
    "  running_str = \"\"\n",
    "  sentence = str(sentence).lower()\n",
    "  for i in sentence.split(\" \"):\n",
    "    running_str+= spell.correction(i) + \" \"\n",
    "  return running_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vG9oQI9deRaq"
   },
   "outputs": [],
   "source": [
    "df = english.head(1000) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 160407,
     "status": "ok",
     "timestamp": 1606989143394,
     "user": {
      "displayName": "Neha Hudait",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiIKoKLUeQlnxxPDix_z2dV5i0n4W4cDcYvJWmzDw=s64",
      "userId": "04178890623871470592"
     },
     "user_tz": 300
    },
    "id": "qtX2GwpxcG2U",
    "outputId": "866152b0-3063-4f9a-dd64-0da180ec8853"
   },
   "outputs": [],
   "source": [
    "df[\"new_message\"] = df[\"Message\"].apply(corrected_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "executionInfo": {
     "elapsed": 152568,
     "status": "ok",
     "timestamp": 1606989143401,
     "user": {
      "displayName": "Neha Hudait",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiIKoKLUeQlnxxPDix_z2dV5i0n4W4cDcYvJWmzDw=s64",
      "userId": "04178890623871470592"
     },
     "user_tz": 300
    },
    "id": "KzeQw3tWc2NJ",
    "outputId": "9aba12c6-98a2-4f42-b8c9-d4fb43c5a136"
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jUURlUCOc_u6"
   },
   "outputs": [],
   "source": [
    "# create a mapping between key words and existing questions that big sis outputs\n",
    "# source doc: https://docs.google.com/document/d/140TJz5oUsLpPQU2-zjLjM9hgo2MTUvYhvKwN8GP6O8I/edit \n",
    "phrases = {\n",
    "            \"love\": [\"Healthy relationships\", \"Am I The One?\", \"Communicating with your partner\", \"Is it love?\", \"Does love really exist?\"],\n",
    "            \"sex\": [\"Choices for contraceptives\", \"Is it ok to be curious about sex?\", \"Curiosity about sex- take the quiz!\", \"What is sex?\", \"Unsure about masturbation\"],\n",
    "            \"relationships\": [\"Am I the One?\", \"Choices for contraceptives\", \"Communicating with your partner\", \"Does he like you?\"],\n",
    "            \"pregnancy\":  [\"How does pregnancy happen?\", \"How much do you know about pregnancy?\", \"Am I pregnant?\", \"If it's my first time can I get pregnant?\", \"Can I get pregnant through oral sex?\"], \n",
    "            \"unknown\": []\n",
    "          }\n",
    "# created key phrases or topics that came up different times within the dataframe\n",
    "phrase_key = [\"love\", \"sex\", \"relationships\", \"pregnancy\", \"unknown\", \"contraception\", \"boyfriend\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 563,
     "status": "ok",
     "timestamp": 1606989151328,
     "user": {
      "displayName": "Neha Hudait",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiIKoKLUeQlnxxPDix_z2dV5i0n4W4cDcYvJWmzDw=s64",
      "userId": "04178890623871470592"
     },
     "user_tz": 300
    },
    "id": "D-_EaIoBjivf",
    "outputId": "ffeb0982-b861-4016-b908-bd1d999a5e29"
   },
   "outputs": [],
   "source": [
    "df[\"new_message\"] = df[\"new_message\"].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cOLHv5yn6j92"
   },
   "source": [
    "# Generating Labels\n",
    "I couldn't find any labeled data which told me what topic a user was talking about when they said a message. For example, \"I want to go out with my bf\" should map to boyfriend. I created a very naive way to generate labels-- essentially, what I did was look for one of 6 words within each message and labeled it as the first occurance of one of those words. This obviously is a flawed way of labeling since we are looking for exact word matches and ignoring context but it was mainly used to display what could occur if we had a topic label. Because of this method, we also have pretty large class imbalance; however, again this is just a proof a concept. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mPYTmidQjnFQ"
   },
   "outputs": [],
   "source": [
    "# finds all of the key phrases defined above\n",
    "def map_sentence_to_word(message):\n",
    "  message = re.sub('[^0-9a-zA-Z]+', ' ', message)\n",
    "  # find key words\n",
    "  message_split = message.split(\" \")\n",
    "  # replace puncuation\n",
    "  for i in message_split:\n",
    "    # lowercase the entire message\n",
    "    curr_string = i.lower()\n",
    "    if curr_string in phrase_key: \n",
    "      return curr_string\n",
    "  return \"unknown\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 697
    },
    "executionInfo": {
     "elapsed": 510,
     "status": "ok",
     "timestamp": 1606989158171,
     "user": {
      "displayName": "Neha Hudait",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiIKoKLUeQlnxxPDix_z2dV5i0n4W4cDcYvJWmzDw=s64",
      "userId": "04178890623871470592"
     },
     "user_tz": 300
    },
    "id": "VIFf8QwBjn0f",
    "outputId": "c97195bf-f081-4f04-cec6-3a4af861ac47"
   },
   "outputs": [],
   "source": [
    "df[\"label\"] = df[\"new_message\"].apply(map_sentence_to_word)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 457,
     "status": "ok",
     "timestamp": 1606989160769,
     "user": {
      "displayName": "Neha Hudait",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiIKoKLUeQlnxxPDix_z2dV5i0n4W4cDcYvJWmzDw=s64",
      "userId": "04178890623871470592"
     },
     "user_tz": 300
    },
    "id": "37e8GqXVjpKX",
    "outputId": "7d24a038-cdd9-4b11-c945-203384d37eff"
   },
   "outputs": [],
   "source": [
    "df[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 606
    },
    "executionInfo": {
     "elapsed": 638,
     "status": "ok",
     "timestamp": 1606989162029,
     "user": {
      "displayName": "Neha Hudait",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiIKoKLUeQlnxxPDix_z2dV5i0n4W4cDcYvJWmzDw=s64",
      "userId": "04178890623871470592"
     },
     "user_tz": 300
    },
    "id": "NzTeWpxvjrCt",
    "outputId": "b252a31b-ff37-42ee-ab63-36a360c86f92"
   },
   "outputs": [],
   "source": [
    "#Drop the unknowns because it would just dilute our data while we are trying to trian our model on it. \n",
    "df = df[df[\"label\"] != \"unknown\"]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UVI-UJLkjsan"
   },
   "outputs": [],
   "source": [
    "SEQ_LEN = 10\n",
    "SEQ_STEP = 2\n",
    "PERCENT_VALIDATION = 0.2\n",
    "ALPHABET = set(string.ascii_letters + string.punctuation + \"123456789\" + ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 564,
     "status": "ok",
     "timestamp": 1606989188432,
     "user": {
      "displayName": "Neha Hudait",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiIKoKLUeQlnxxPDix_z2dV5i0n4W4cDcYvJWmzDw=s64",
      "userId": "04178890623871470592"
     },
     "user_tz": 300
    },
    "id": "WY5ByuOImDJp",
    "outputId": "6e2f2d84-a4c2-4978-b656-5c26105f752f"
   },
   "outputs": [],
   "source": [
    "# begin to create the inputs for the LSTM \n",
    "messages = list(df[\"new_message\"])\n",
    "\n",
    "for i in range(len(messages)):\n",
    "  messages[i] = re.sub('[^0-9a-zA-Z]+', ' ', messages[i])\n",
    "\n",
    "labels = list(df[\"label\"])\n",
    "messages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kjxzkKU376DC"
   },
   "source": [
    "# Making the Input to the LSTM Model\n",
    "We create a series of sequences. Each sequence is SEQ_LEN characters long. After creating our sequences, we make a mapping from index to character and character to index for the X data. We also create a mapping from index to phrase (\"boyfriend\" , \"love\" etc) and a mapping from phrase to index-- note that the phrase is what we are predicting.  Fianlly, we utilize this mapping to make the LSTM input which is number of sequences x number of elements in sequence x number of characters in alphabet "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 372,
     "status": "ok",
     "timestamp": 1606989192367,
     "user": {
      "displayName": "Neha Hudait",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiIKoKLUeQlnxxPDix_z2dV5i0n4W4cDcYvJWmzDw=s64",
      "userId": "04178890623871470592"
     },
     "user_tz": 300
    },
    "id": "bqDgiKiBmeUV",
    "outputId": "768bc8f7-4ab2-48ec-d21b-b05c5a25d45b"
   },
   "outputs": [],
   "source": [
    "sequences = []\n",
    "label_seq = []\n",
    "for i in range(len(messages)):\n",
    "  message = messages[i]\n",
    "  for j in range(0, len(message)-SEQ_LEN, SEQ_STEP):\n",
    "    sequences.append(message[j:j+SEQ_LEN])\n",
    "    label_seq.append(labels[i])\n",
    "len(label_seq), len(sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 418,
     "status": "ok",
     "timestamp": 1606989193691,
     "user": {
      "displayName": "Neha Hudait",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiIKoKLUeQlnxxPDix_z2dV5i0n4W4cDcYvJWmzDw=s64",
      "userId": "04178890623871470592"
     },
     "user_tz": 300
    },
    "id": "5AW_-hwozj2e",
    "outputId": "0df6390b-bf59-433e-8050-b1f05d370677"
   },
   "outputs": [],
   "source": [
    "sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T3Tl6YtzmfOx"
   },
   "outputs": [],
   "source": [
    "characters= sorted(list(set(ALPHABET)))\n",
    "index_to_char = {}\n",
    "char_to_index = {}\n",
    "# creating a mapping\n",
    "for idx, char in enumerate(characters):\n",
    "  index_to_char[idx] = char\n",
    "  char_to_index[char] = idx\n",
    "\n",
    "index_to_phrase  = {}\n",
    "phrase_to_index = {}\n",
    "for idx, phrase in enumerate(phrase_key):\n",
    "  index_to_phrase[idx] = phrase\n",
    "  phrase_to_index[phrase] = idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6ZO-glIosQNI"
   },
   "outputs": [],
   "source": [
    "X = np.zeros((len(sequences), SEQ_LEN, len(characters)))\n",
    "y = np.zeros((len(label_seq), len(phrase_key)))\n",
    "for i, seq in enumerate(sequences):\n",
    "  for j, char in enumerate(sequences[i]):\n",
    "    X[i, j, char_to_index[char]] = 1\n",
    "  y[i, phrase_to_index[label_seq[i]]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 528,
     "status": "ok",
     "timestamp": 1606989259141,
     "user": {
      "displayName": "Neha Hudait",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiIKoKLUeQlnxxPDix_z2dV5i0n4W4cDcYvJWmzDw=s64",
      "userId": "04178890623871470592"
     },
     "user_tz": 300
    },
    "id": "JurfNLv9sQru",
    "outputId": "cfdeca96-9a79-4ef8-f2a3-e0bf291b2991"
   },
   "outputs": [],
   "source": [
    "# input to the LSTM\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_YjXtHYOtN68"
   },
   "outputs": [],
   "source": [
    "#Created training data and validation data \n",
    "idxes = np.random.permutation(X.shape[0])\n",
    "val_num = int(PERCENT_VALIDATION*len(X))\n",
    "X = X[idxes]\n",
    "X_train = X[val_num:]\n",
    "X_val = X[:val_num]\n",
    "y = y[idxes]\n",
    "y_train = y[val_num:]\n",
    "y_val = y[:val_num]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AXYajNuy84rM"
   },
   "source": [
    "# Created the LSTM\n",
    "Here is a below possibility of how the LSTM could look. I achieved fairly low loss on this dummy daa; however, this will obviously change when we have real labels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JU4pUGUKvvSi"
   },
   "outputs": [],
   "source": [
    "def build_model(num_chars, output_chars):\n",
    "    model = Sequential()\n",
    "    model.add(Bidirectional(LSTM(64, input_shape=(SEQ_LEN, num_chars), return_sequences=True,unit_forget_bias=True)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(rate=.1))\n",
    "    model.add(Bidirectional(LSTM(128,return_sequences=True,unit_forget_bias=True)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(rate=.1))\n",
    "    model.add(Bidirectional(LSTM(256,return_sequences=True,unit_forget_bias=True)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(rate=.1))\n",
    "    model.add(Bidirectional(LSTM(128)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(rate=.2))\n",
    "    model.add(Dense(output_chars, activation='softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='RMSprop')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5733,
     "status": "ok",
     "timestamp": 1606989273104,
     "user": {
      "displayName": "Neha Hudait",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiIKoKLUeQlnxxPDix_z2dV5i0n4W4cDcYvJWmzDw=s64",
      "userId": "04178890623871470592"
     },
     "user_tz": 300
    },
    "id": "VBJU3k54v7wQ",
    "outputId": "2137647f-59a6-4697-bae3-b21db19a3fa9"
   },
   "outputs": [],
   "source": [
    "print(\"Making New Model\")\n",
    "model = build_model(len(characters), len(phrase_to_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 79454,
     "status": "ok",
     "timestamp": 1606989353567,
     "user": {
      "displayName": "Neha Hudait",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiIKoKLUeQlnxxPDix_z2dV5i0n4W4cDcYvJWmzDw=s64",
      "userId": "04178890623871470592"
     },
     "user_tz": 300
    },
    "id": "gI_l14AixeWg",
    "outputId": "f5ae7b3f-648c-4b2d-efc3-0565bbb3005c"
   },
   "outputs": [],
   "source": [
    "\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 20 \n",
    "\n",
    "trained_model = model.fit(X_train, y_train, batch_size=BATCH_SIZE, epochs= EPOCHS, validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2AeByBL19H5n"
   },
   "source": [
    "# Testing on a random point\n",
    "Below I wrote a sentence. Below, we convert it into sequences, then make it into a valid input for our LSTM and predict. We receive predictions for every subsequence of that sentence and we pick the majority vote \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LOwC9yND2Tbs"
   },
   "outputs": [],
   "source": [
    "test_message = [\"Tell my bf I love him\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 562,
     "status": "ok",
     "timestamp": 1606989370304,
     "user": {
      "displayName": "Neha Hudait",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiIKoKLUeQlnxxPDix_z2dV5i0n4W4cDcYvJWmzDw=s64",
      "userId": "04178890623871470592"
     },
     "user_tz": 300
    },
    "id": "0xTASY2z3lCR",
    "outputId": "0dcdb270-4b13-4670-88c3-40d0501b2214"
   },
   "outputs": [],
   "source": [
    "test_seqs = []\n",
    "for i in range(len(test_message)):\n",
    "  message = test_message[i]\n",
    "  for j in range(0, len(message)-SEQ_LEN, SEQ_STEP):\n",
    "    test_seqs.append(message[j:j+SEQ_LEN])\n",
    "test_seqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HdleTTEs479S"
   },
   "outputs": [],
   "source": [
    "X = np.zeros((len(test_seqs), SEQ_LEN, len(characters)))\n",
    "for i, seq in enumerate(test_seqs):\n",
    "  for j, char in enumerate(test_seqs[i]):\n",
    "    X[i, j, char_to_index[char]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ssLrdZrs51xV"
   },
   "outputs": [],
   "source": [
    "from scipy.stats import mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2771,
     "status": "ok",
     "timestamp": 1606989379334,
     "user": {
      "displayName": "Neha Hudait",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiIKoKLUeQlnxxPDix_z2dV5i0n4W4cDcYvJWmzDw=s64",
      "userId": "04178890623871470592"
     },
     "user_tz": 300
    },
    "id": "eHiocn9W37t1",
    "outputId": "fceedce7-7c5f-419f-e3cd-e37ca9734b61"
   },
   "outputs": [],
   "source": [
    "preds = model.predict(X)\n",
    "votes = []\n",
    "for i in range(len(preds)):\n",
    "  votes.append(np.argmax(preds[i]))\n",
    "print(index_to_phrase[mode(votes)[0][0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gEtFXS-X4Qd2"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "english_language_modeling.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
